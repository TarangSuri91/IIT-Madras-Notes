{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Write a function add_one(X) to include first column with all elements 1 in X.\n",
    " \n",
    "  1. Inputs: A matrix X\n",
    "  2. Output: updated matrix with a column having elements 1 added as first column to X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_one(X):  \n",
    "    X = np.column_stack((np.ones(X.shape[0]), X))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Write a function multiply(X,w) to Multiply feature matrix(X) and weight vector(w) after addition of dummy feature to feature matrix.\n",
    "\n",
    " - Inputs: Feature matrix X and weight vector w\n",
    " - Output: Product of X and w after adding dummy feature to feature matrix X. If the dimensions are not consistent return None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply(X, w):\n",
    "    X = np.column_stack((np.ones(X.shape[0]), X))\n",
    "    if X.shape[1] == w.shape[0]:\n",
    "        return X @ w\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Write a function loss(X,w,y) which takes feature matrix(X), weight vector(w) and output label vector(y) and returns sum squared loss while implementing regression model.(Note: Do necessary preprocessing of X)\n",
    " \n",
    "  1. Inputs: Feature matrix X and weight vector w and output label vector y\n",
    "  2. Output: sum squared loss if dimensions of inputs are consistent, otherwise None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(X, w, y):\n",
    "    X = np.column_stack((np.ones(X.shape[0]), X))\n",
    "    e = (X @ w) - y\n",
    "    return 0.5 * (e.T @ e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graded Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Write a function compatibility(X,w) to find whether X and w can be multiplied or not.\n",
    " \n",
    "  1. Inputs: Feature matrix X and weight vector w,\n",
    "  2. Output: return \"C\" if X and w can be multiplied otherwise None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compatibility(X, w):\n",
    "    X = np.column_stack((np.ones(X.shape[0]), X))\n",
    "    if X.shape[1] == w.shape[0]:\n",
    "        return \"C\"\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Write a function gradient(X,w,y) to calculate gradient of loss function w.r.t weight vector given that X is the feature matrix, w is the weight vector and y is the output vector.\n",
    "(Note: do necessary preprocessing of X)\n",
    " \n",
    "  1. Inputs: Feature matrix X, weight vector w, and output label vector y.\n",
    "  2. Output: gradient if dimesnsions of inputs are consistent, otherwise None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(X, w, y):\n",
    "    X = np.column_stack((np.ones(X.shape[0]), X))\n",
    "    if X.shape[1] == w.shape[0]:\n",
    "        return X.T @ (X @ w - y)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Write a function weight_update(X,w,y,lr) to get updated weight after one iteration of gradient descent given that X is the feature matrix, w is the weight vector and y is the output label vector.\n",
    "(Note: Do necessary preprocessing of X)\n",
    " \n",
    "  1. Inputs: Feature matrix X, weight vector w, output label vector y and learning rate lr\n",
    "  2. Output: weight updates after gradient calculation if dimensions of inputs are consistent, otherwise None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(X, w, y):\n",
    "    X = np.column_stack((np.ones(X.shape[0]), X))\n",
    "    if X.shape[1] == w.shape[0]:\n",
    "        return X.T @ (X @ w - y)\n",
    "    return None\n",
    "\n",
    "def weight_update(X, w, y, lr):\n",
    "    g = gradient(X, w, y)\n",
    "    if g:\n",
    "        return w - g * lr\n",
    "    return None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
