{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week10.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5V-8S1rfBmke"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split, cross_validate, cross_val_score, ShuffleSplit\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
        "from sklearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "id": "LuUbOq80CL2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ],
      "metadata": {
        "id": "H4HPwc4BC-f1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Flattening 28 * 28 pixels to 784 features.\n",
        "X_train = X_train.reshape(60000, 28 * 28)\n",
        "X_test = X_test.reshape(10000, 28 * 28)\n",
        "\n",
        "X_train = X_train/255\n",
        "X_test = X_test/255"
      ],
      "metadata": {
        "id": "oS2ctlJWDFAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ],
      "metadata": {
        "id": "B2ijSEX4DRq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "8znvz6svDgt1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_classifiers(estimator, X_train, y_train, cv, name):\n",
        "  estimator.fit(X_train, y_train)\n",
        "  cv_train_score = cross_val_score(estimator, X_train, y_train, cv=cv, scoring='f1_macro')\n",
        "  print(f\"On an average, {name} model has f1 score of {cv_train_score.mean():.3f} +/- {cv_train_score.std():.3f} on training set\")"
      ],
      "metadata": {
        "id": "I8nbW4vJDsYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval(estimator, X_test, y_test):\n",
        "  y_pred = estimator.predict(X_test)\n",
        "  print(classification_report(y_test, y_pred))\n",
        "  disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_test, y_pred))\n",
        "  disp.plot()\n",
        "  plt.title('Ã‡onfusion Matrix')\n",
        "  plt.show()  "
      ],
      "metadata": {
        "id": "vFdEt3HsEPoc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decision Trees on MNIST multiclass classification"
      ],
      "metadata": {
        "id": "C57G3qQwEoqn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dt_pipeline = Pipeline([('classifier', DecisionTreeClassifier())])\n",
        "train_classifiers(dt_pipeline, X_train, y_train, cv, \"decision tree\")"
      ],
      "metadata": {
        "id": "0cCFKFGuEtiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval(dt_pipeline, X_test, y_test)"
      ],
      "metadata": {
        "id": "QePuY3MWFQRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MNIST classification with Bagging"
      ],
      "metadata": {
        "id": "wZxS7PdUXYM9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bagging_pipeline = Pipeline([('classifier', BaggingClassifier())])\n",
        "train_classifiers(bagging_pipeline, X_train, y_train, cv, 'bagging')"
      ],
      "metadata": {
        "id": "sftwSAVcXa7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval(bagging_pipeline, X_test, y_test)"
      ],
      "metadata": {
        "id": "H6AGqtD9XutG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MNIST classification with Random Forest"
      ],
      "metadata": {
        "id": "tbKvdMeHX1wt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_pipeline = Pipeline([('classifier', RandomForestClassifier())])\n",
        "train_classifiers(rf_pipeline, X_train, y_train, cv, 'random forest')"
      ],
      "metadata": {
        "id": "W01QqaebX1wt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval(rf_pipeline, X_test, y_test)"
      ],
      "metadata": {
        "id": "e4DWaAgsX1wu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# California Housing Dataset"
      ],
      "metadata": {
        "id": "Fflhqj5tGtnK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.model_selection import cross_validate, train_test_split, RandomizedSearchCV, ShuffleSplit\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "np.random.seed(306)"
      ],
      "metadata": {
        "id": "XFWGHtJ8Gs4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "bqEJoQqSHV3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features, labels = fetch_california_housing(as_frame=True, return_X_y=True)\n",
        "labels *= 100"
      ],
      "metadata": {
        "id": "7DTtszIqHeFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "com_train_features, test_features, com_train_labels, test_labels = train_test_split(features, labels, random_state=42)\n",
        "train_features, dev_features, train_labels, dev_labels = train_test_split(com_train_features, com_train_labels, random_state=42)"
      ],
      "metadata": {
        "id": "oA1Ia1SfHyn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_regressor(estimator, X_train, y_train, cv, name):\n",
        "  cv_results = cross_validate(estimator, X_train, y_train, cv=cv, scoring='neg_mean_absolute_error', return_train_score=True, return_estimator=True)\n",
        "  cv_train_error = -1 * (cv_results['train_score'])\n",
        "  cv_test_error = -1 * (cv_results['test_score'])\n",
        "  print(f'On an average, {name} makes an error of {cv_train_error.mean():.3f}k +/- {cv_train_error.std():.3f}k on the training set')\n",
        "  print(f'On an average, {name} makes an error of {cv_test_error.mean():.3f}k +/- {cv_test_error.std():.3f}k on the test set')"
      ],
      "metadata": {
        "id": "OiNlvaHsIKzT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_regressor(DecisionTreeRegressor(), com_train_features, com_train_labels, cv, 'decision tree regressor')"
      ],
      "metadata": {
        "id": "YV4HxEitI6ng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_regressor(BaggingRegressor(), com_train_features, com_train_labels, cv, 'bagging regressor')"
      ],
      "metadata": {
        "id": "r7bN2zpyJHa_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_regressor(RandomForestRegressor(), com_train_features, com_train_labels, cv, 'random forest regressor')"
      ],
      "metadata": {
        "id": "PRj2qOaZJsXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyper-parameter tuning"
      ],
      "metadata": {
        "id": "PHGRpDKsSLlP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_distributions = {'n_estimators': [1,2,5,10,20,40,100,200,500], 'max_leaf_nodes': [2,5,10,20,50,100]}\n",
        "search_cv = RandomizedSearchCV(RandomForestRegressor(), param_distributions=param_distributions, \n",
        "                               scoring='neg_mean_absolute_error', n_iter=10, random_state=10)\n",
        "\n",
        "search_cv.fit(com_train_features, com_train_labels)"
      ],
      "metadata": {
        "id": "hck-s8HNSPlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns = [f'param_{name}' for name in param_distributions.keys()]\n",
        "columns += ['mean_test_error', 'std_test_error']\n",
        "cv_results = pd.DataFrame(search_cv.cv_results_)\n",
        "cv_results['mean_test_error'] = -cv_results['mean_test_score']\n",
        "cv_results['std_test_error'] = -cv_results['std_test_score']\n",
        "cv_results[columns].sort_values(by='mean_test_error')"
      ],
      "metadata": {
        "id": "eOxDvxhHT9VF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "error = -search_cv.score(test_features, test_labels)\n",
        "print(f'On average, our random forest regressor makes an error of {error: .2f}k$')"
      ],
      "metadata": {
        "id": "AfvGQq_IVxUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MNIST classification with AdaBoost and GradientBoost"
      ],
      "metadata": {
        "id": "tPsdVbL6qvvW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_validate, cross_val_score, ShuffleSplit\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "metadata": {
        "id": "QcxNwglwq1Vn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "id": "jgFHrG8-rSJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ],
      "metadata": {
        "id": "LyqLOPu5rSJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Flattening 28 * 28 pixels to 784 features.\n",
        "X_train = X_train.reshape(60000, 28 * 28)\n",
        "X_test = X_test.reshape(10000, 28 * 28)\n",
        "\n",
        "X_train = X_train/255\n",
        "X_test = X_test/255"
      ],
      "metadata": {
        "id": "VWRdTBkprSJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ],
      "metadata": {
        "id": "ncF_jWGsrSJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "wVzqbMYVrSJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_classifiers(estimator, X_train, y_train, cv, name):\n",
        "  estimator.fit(X_train, y_train)\n",
        "  cv_train_score = cross_val_score(estimator, X_train, y_train, cv=cv, scoring='f1_macro')\n",
        "  print(f\"On an average, {name} model has f1 score of {cv_train_score.mean():.3f} +/- {cv_train_score.std():.3f} on training set\")"
      ],
      "metadata": {
        "id": "jU3j565qrcQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval(estimator, X_test, y_test):\n",
        "  y_pred = estimator.predict(X_test)\n",
        "  print(classification_report(y_test, y_pred))\n",
        "  disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_test, y_pred))\n",
        "  disp.plot()\n",
        "  plt.title('Ã‡onfusion Matrix')\n",
        "  plt.show()  "
      ],
      "metadata": {
        "id": "hOeL9vOVrmL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AdaBoostClassifier"
      ],
      "metadata": {
        "id": "unb4Qj2EsWJP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "abc_pipeline = Pipeline([('abc_classifier', AdaBoostClassifier())])\n",
        "train_classifiers(abc_pipeline, X_train, y_train, cv, 'AdaBoostClassifier')"
      ],
      "metadata": {
        "id": "S9hRX3e8rsep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval(abc_pipeline, X_test, y_test)"
      ],
      "metadata": {
        "id": "s6bHez_6sGC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GradientBoostingClassifier"
      ],
      "metadata": {
        "id": "rkMB-Woesaef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gbc_pipeline = Pipeline([('gbc_classifier', GradientBoostingClassifier())])\n",
        "train_classifiers(gbc_pipeline, X_train, y_train, cv, 'GradientBoostingClassifier')"
      ],
      "metadata": {
        "id": "jDo-skg5sfN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval(gbc_pipeline, X_test, y_test)"
      ],
      "metadata": {
        "id": "a_rGQm44sfN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost"
      ],
      "metadata": {
        "id": "iyS1c1fqsxmd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier"
      ],
      "metadata": {
        "id": "LTHjoBc_s2bf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xbc_pipeline = Pipeline([('xbc_classifier', XGBClassifier())])\n",
        "train_classifiers(xbc_pipeline, X_train, y_train, cv, 'XGBClassifier')"
      ],
      "metadata": {
        "id": "XZyUqALhs8N-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval(xbc_pipeline, X_test, y_test)"
      ],
      "metadata": {
        "id": "Za_0kYCmtEQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# California Housing with AdaBoost and GradientBoost"
      ],
      "metadata": {
        "id": "Fl16ioa9wFyH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.ensemble import AdaBoostRegressor, GradientBoostingRegressor\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_validate, RandomizedSearchCV, ShuffleSplit\n",
        "from sklearn.metrics import mean_absolute_error"
      ],
      "metadata": {
        "id": "3IOGkYuJwA8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(306)"
      ],
      "metadata": {
        "id": "D-GCEKPSwZ2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "m0-A5Z5owj7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features, labels = fetch_california_housing(as_frame=True, return_X_y=True)\n",
        "labels *= 100"
      ],
      "metadata": {
        "id": "Asx5gZcrw2dT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "com_train_features, test_features, com_train_labels, test_labels = train_test_split(features, labels, random_state=42)\n",
        "train_features, dev_features, train_labels, dev_labels = train_test_split(com_train_features, com_train_labels, random_state=42)"
      ],
      "metadata": {
        "id": "TsnRZIzlw2dV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_regressor(estimator, X_train, y_train, cv, name):\n",
        "  cv_results = cross_validate(estimator, X_train, y_train, cv=cv, scoring='neg_mean_absolute_error', return_train_score=True, return_estimator=True)\n",
        "  cv_train_error = -1 * (cv_results['train_score'])\n",
        "  cv_test_error = -1 * (cv_results['test_score'])\n",
        "  print(f'On an average, {name} makes an error of {cv_train_error.mean():.3f}k +/- {cv_train_error.std():.3f}k on the training set')\n",
        "  print(f'On an average, {name} makes an error of {cv_test_error.mean():.3f}k +/- {cv_test_error.std():.3f}k on the test set')"
      ],
      "metadata": {
        "id": "fYTwIopww2dV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AdaBoostRegressor"
      ],
      "metadata": {
        "id": "dTt8PAicw6v6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_regressor(AdaBoostRegressor(), com_train_features, com_train_labels, cv, 'AdaBoostRegressor')"
      ],
      "metadata": {
        "id": "k1XhEKdiw5lW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_regressor(GradientBoostingRegressor(), com_train_features, com_train_labels, cv, 'GradientBoostingRegressor')"
      ],
      "metadata": {
        "id": "aWptFaedxVfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBRegressor\n",
        "xgb = XGBRegressor(objective='reg:squarederror')\n",
        "train_regressor(xgb, com_train_features, com_train_labels, cv, 'XGBRegressor')"
      ],
      "metadata": {
        "id": "A5IrknNJxdTL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}